#!/usr/bin/env python3
"""
Hugging Faceã®SetFit/amazon_reviews_multi_jaãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€
MongoDBã«å•†å“ãŠã‚ˆã³ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨ã—ã¦æŠ•å…¥ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚

å‚è€ƒ: https://note.com/eurekachan/n/nbde77c119945
"""

from __future__ import annotations

import argparse
import json
import os
import random
import re
import sys
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Dict, Iterable, List, Tuple
from urllib.request import Request, urlopen

try:
    from dotenv import load_dotenv  # type: ignore
except ImportError:  # pragma: no cover - optional dependency
    load_dotenv = None

from pymongo import MongoClient
from pymongo.server_api import ServerApi

if load_dotenv is not None:
    load_dotenv()

sys.stdout.reconfigure(encoding="utf-8", errors="ignore")
sys.stderr.reconfigure(encoding="utf-8", errors="ignore")

DATASET_URLS = {
    "train": "https://huggingface.co/datasets/SetFit/amazon_reviews_multi_ja/resolve/main/train.jsonl",
    "validation": "https://huggingface.co/datasets/SetFit/amazon_reviews_multi_ja/resolve/main/validation.jsonl",
    "test": "https://huggingface.co/datasets/SetFit/amazon_reviews_multi_ja/resolve/main/test.jsonl"
}

ANNOTATION_TYPES = ["insightful", "unclear", "empathy", "helpful"]

PRODUCT_CONFIGS = [
    {
        "id": "prod-001",
        "slug": "wireless-earbuds-pro",
        "category": "å®¶é›»ãƒ»ã‚«ãƒ¡ãƒ©",
        "image": "https://images.unsplash.com/photo-1590658268037-6bf12165a8df?w=400",
        "keywords": ["ã‚¤ãƒ¤ãƒ›ãƒ³", "ãƒ˜ãƒƒãƒ‰ãƒ›ãƒ³", "ãƒ¯ã‚¤ãƒ¤ãƒ¬ã‚¹", "éŸ³è³ª", "ãƒã‚¤ã‚º"]
    },
    {
        "id": "prod-002",
        "slug": "smart-watch-x1",
        "category": "å®¶é›»ãƒ»ã‚«ãƒ¡ãƒ©",
        "image": "https://images.unsplash.com/photo-1523275335684-37898b6baf30?w=400",
        "keywords": ["ã‚¹ãƒãƒ¼ãƒˆã‚¦ã‚©ãƒƒãƒ", "è…•æ™‚è¨ˆ", "å¿ƒæ‹", "ç¡çœ ", "ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹"]
    },
    {
        "id": "prod-003",
        "slug": "mechanical-keyboard-rgb",
        "category": "ãƒ‘ã‚½ã‚³ãƒ³ãƒ»å‘¨è¾ºæ©Ÿå™¨",
        "image": "https://images.unsplash.com/photo-1587829741301-dc798b83add3?w=400",
        "keywords": ["ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰", "ã‚¿ã‚¤ãƒ”ãƒ³ã‚°", "ã‚­ãƒ¼", "æ‰“éµ", "ãƒ¡ã‚«ãƒ‹ã‚«ãƒ«"]
    }
]

COLLECTION_PRODUCTS = "products"
COLLECTION_REVIEWS = "reviews"

random.seed(42)


def download_file(url: str, dest: Path, overwrite: bool = False) -> None:
    if dest.exists() and not overwrite:
        return

    dest.parent.mkdir(parents=True, exist_ok=True)
    req = Request(url, headers={"User-Agent": "Mozilla/5.0"})
    with urlopen(req) as response, dest.open("wb") as f:
        chunk_size = 1024 * 1024
        while True:
            chunk = response.read(chunk_size)
            if not chunk:
                break
            f.write(chunk)


def iter_dataset(paths: Dict[str, Path]) -> Iterable[Tuple[str, Dict[str, object]]]:
    for split, path in paths.items():
        with path.open("r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                record = json.loads(line)
                record["split"] = split
                yield split, record


def classify_sentiment(label: int) -> str | None:
    if label <= 1:
        return "negative"
    if label >= 3:
        return "positive"
    return None


def create_title(text: str) -> str:
    cleaned = text.strip().splitlines()[0] if text.strip() else ""
    if not cleaned:
        return "ãƒ¬ãƒ“ãƒ¥ãƒ¼"
    first_sentence = re.split(r"[ã€‚ï¼ï¼Ÿ!?\n]", cleaned, maxsplit=1)[0]
    first_sentence = first_sentence.strip()
    if not first_sentence:
        first_sentence = cleaned.strip()
    return first_sentence[:30] + ("â€¦" if len(first_sentence) > 30 else "")


def split_into_sentences(text: str) -> List[str]:
    sentences: List[str] = []
    buffer: List[str] = []
    for char in text:
        buffer.append(char)
        if char in ("ã€‚", "ï¼", "?", "ï¼Ÿ", "\n"):
            sentence = "".join(buffer).strip()
            buffer.clear()
            if sentence:
                sentences.append(sentence)
    if buffer:
        tail = "".join(buffer).strip()
        if tail:
            sentences.append(tail)
    return sentences


def build_sentence_entities(review_id: str, sentences: List[str]) -> List[Dict[str, object]]:
    entities = []
    for idx, sentence in enumerate(sentences, start=1):
        entities.append(
            {
                "id": f"{review_id}-sentence-{idx:02d}",
                "text": sentence,
                "annotations": [{"type": ann_type, "count": 0} for ann_type in ANNOTATION_TYPES],
            }
        )
    return entities


def random_datetime_within(days: int = 365) -> datetime:
    now = datetime.now(timezone.utc)
    delta_days = random.randint(0, days)
    delta_minutes = random.randint(0, 23 * 60 + 59)
    return now - timedelta(days=delta_days, minutes=delta_minutes)


def build_review_document(
    record: Dict[str, object],
    product: Dict[str, object],
    review_index: int,
    sentiment: str
) -> Dict[str, object]:
    dataset_label = int(record["label"])
    rating = max(1, min(5, dataset_label + 1))
    review_id = f"{product['id']}-rev-{review_index:04d}"
    created_at = random_datetime_within()
    total_votes = random.randint(0, 120)
    if total_votes == 0:
        helpful_votes = 0
    elif sentiment == "positive":
        helpful_votes = random.randint(max(0, total_votes // 2), total_votes)
    else:
        helpful_votes = random.randint(0, total_votes // 2)

    sentences = split_into_sentences(record["text"])

    return {
        "reviewId": review_id,
        "productId": product["id"],
        "productSlug": product["slug"],
        "datasetId": record["id"],
        "datasetLabel": dataset_label,
        "datasetSplit": record["split"],
        "sentiment": sentiment,
        "rating": rating,
        "title": create_title(record["text"]),
        "content": record["text"],
        "userId": f"user-{review_id}",
        "userName": f"ãƒ¦ãƒ¼ã‚¶ãƒ¼{review_index:04d}",
        "userAvatar": f"https://i.pravatar.cc/150?u={review_id}",
        "verifiedPurchase": random.random() < 0.85,
        "helpfulVotes": helpful_votes,
        "totalVotes": total_votes,
        "createdAt": created_at,
        "updatedAt": created_at,
        "language": "ja",
        "sentences": build_sentence_entities(review_id, sentences),
    }


def summarize_text(text: str, max_length: int = 220) -> str:
    collapsed = re.sub(r"\s+", " ", text).strip()
    if len(collapsed) <= max_length:
        return collapsed
    return collapsed[:max_length].rstrip() + "â€¦"


def extract_product_name_from_reviews(reviews: List[Dict[str, object]]) -> str:
    """ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰å•†å“åã‚’æ¨æ¸¬"""
    # ãƒ¬ãƒ“ãƒ¥ãƒ¼æœ¬æ–‡ã‹ã‚‰å•†å“åã‚‰ã—ãå˜èªã‚’æŠ½å‡º
    product_keywords = {}
    for review in reviews:
        text = str(review.get("content", ""))
        # ä¸€èˆ¬çš„ãªå•†å“åãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
        # ã€Œâ—‹â—‹ã‚’è³¼å…¥ã€ã€Œâ—‹â—‹ãŒå±Šã„ãŸã€ã€Œâ—‹â—‹ã‚’ä½¿ã£ãŸã€ãªã©ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        patterns = [
            r"([^ã€‚ã€\s]{2,15}?)(ã‚’|ãŒ|ã®)(è³¼å…¥|å±Šã„ãŸ|ä½¿ã£ãŸ|ä½¿ç”¨|è©¦ã—ãŸ)",
            r"([^ã€‚ã€\s]{2,15}?)(ã®)(ãƒ¬ãƒ“ãƒ¥ãƒ¼|æ„Ÿæƒ³|è©•ä¾¡)",
        ]
        for pattern in patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                if isinstance(match, tuple):
                    keyword = match[0] if match[0] else ""
                else:
                    keyword = match
                if len(keyword) >= 2 and len(keyword) <= 15:
                    product_keywords[keyword] = product_keywords.get(keyword, 0) + 1
    
    if product_keywords:
        # æœ€ã‚‚é »å‡ºã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å•†å“åã¨ã—ã¦ä½¿ç”¨
        most_common = max(product_keywords.items(), key=lambda x: x[1])
        return most_common[0]
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®æœ€åˆã®æ–‡ã‹ã‚‰æŠ½å‡º
    if reviews:
        first_review = str(reviews[0].get("content", ""))
        first_sentence = re.split(r"[ã€‚ï¼ï¼Ÿ!?\n]", first_review, maxsplit=1)[0]
        # æœ€åˆã®10æ–‡å­—ç¨‹åº¦ã‚’å•†å“åã¨ã—ã¦ä½¿ç”¨
        return first_sentence[:15].strip()
    
    return "å•†å“"


def infer_category_from_reviews(reviews: List[Dict[str, object]]) -> str:
    """ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªã‚’æ¨æ¸¬"""
    category_keywords = {
        "å®¶é›»ãƒ»ã‚«ãƒ¡ãƒ©": ["å……é›»", "é›»æº", "ãƒãƒƒãƒ†ãƒªãƒ¼", "ã‚¤ãƒ¤ãƒ›ãƒ³", "ãƒ˜ãƒƒãƒ‰ãƒ›ãƒ³", "ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼", "ã‚«ãƒ¡ãƒ©", "ãƒ¬ãƒ³ã‚º", "ãƒ†ãƒ¬ãƒ“", "å†·è”µåº«", "æ´—æ¿¯æ©Ÿ"],
        "ãƒ‘ã‚½ã‚³ãƒ³ãƒ»å‘¨è¾ºæ©Ÿå™¨": ["ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰", "ãƒã‚¦ã‚¹", "ãƒ¢ãƒ‹ã‚¿ãƒ¼", "PC", "ãƒ‘ã‚½ã‚³ãƒ³", "ãƒãƒ¼ãƒˆ", "ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆ", "USB", "ã‚±ãƒ¼ãƒ–ãƒ«", "å……é›»å™¨"],
        "ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ãƒ»ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆ": ["iPhone", "Android", "ã‚¹ãƒãƒ›", "ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³", "ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆ", "ã‚¢ãƒ—ãƒª", "ç”»é¢", "ã‚¿ãƒƒãƒ"],
        "ãƒ›ãƒ“ãƒ¼ãƒ»ã‚²ãƒ¼ãƒ ": ["ã‚²ãƒ¼ãƒ ", "ãƒ—ãƒ¬ã‚¤", "ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼", "ã‚½ãƒ•ãƒˆ", "ãƒ•ã‚£ã‚®ãƒ¥ã‚¢", "ãƒ—ãƒ©ãƒ¢ãƒ‡ãƒ«"],
        "æœ¬ãƒ»é›‘èªŒãƒ»ã‚³ãƒŸãƒƒã‚¯": ["æœ¬", "æ›¸ç±", "é›‘èªŒ", "ã‚³ãƒŸãƒƒã‚¯", "ãƒãƒ³ã‚¬", "å°èª¬"],
        "é£Ÿå“ãƒ»é£²æ–™": ["é£Ÿã¹", "é£²ã¿", "å‘³", "ãŠã„ã—ã„", "ã¾ãšã„", "æ–™ç†", "ãƒ¬ã‚·ãƒ”"],
        "ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³": ["æœ", "é´", "ãƒãƒƒã‚°", "ã‚¢ã‚¯ã‚»ã‚µãƒªãƒ¼", "ã‚µã‚¤ã‚º", "ç€ç”¨"],
        "ç¾å®¹ãƒ»å¥åº·": ["åŒ–ç²§", "ã‚¹ã‚­ãƒ³ã‚±ã‚¢", "ã‚·ãƒ£ãƒ³ãƒ—ãƒ¼", "æ­¯ç£¨ã", "ã‚µãƒ—ãƒªãƒ¡ãƒ³ãƒˆ"],
    }
    
    text_content = " ".join(str(r.get("content", "")) for r in reviews)
    category_scores = {}
    
    for category, keywords in category_keywords.items():
        score = sum(1 for keyword in keywords if keyword in text_content)
        if score > 0:
            category_scores[category] = score
    
    if category_scores:
        return max(category_scores.items(), key=lambda x: x[1])[0]
    
    return "ãã®ä»–"


def build_product_document(
    config: Dict[str, str],
    reviews: List[Dict[str, object]]
) -> Dict[str, object]:
    average_rating = round(sum(review["rating"] for review in reviews) / len(reviews), 2)
    
    # ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰å®Ÿéš›ã®å•†å“åã‚’æŠ½å‡º
    extracted_name = extract_product_name_from_reviews(reviews)
    if extracted_name and extracted_name != "å•†å“":
        product_name = extracted_name
    else:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ç”Ÿæˆ
        positive_reviews = [review for review in reviews if review["sentiment"] == "positive"]
        representative_review = positive_reviews[0] if positive_reviews else reviews[0]
        representative_text = str(representative_review["content"])
        product_name = create_title(representative_text)
    
    # ã‚«ãƒ†ã‚´ãƒªã‚’æ¨æ¸¬
    inferred_category = infer_category_from_reviews(reviews)
    category = inferred_category if inferred_category != "ãã®ä»–" else config["category"]
    
    # èª¬æ˜æ–‡ã‚’ç”Ÿæˆ
    all_reviews_text = " ".join(str(r.get("content", "")) for r in reviews[:5])
    description = summarize_text(all_reviews_text, 220)
    
    # ä¾¡æ ¼ã‚’æ¨æ¸¬ï¼ˆãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å†…å®¹ã‹ã‚‰ï¼‰
    # å¹³å‡è©•ä¾¡ã¨ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ã«åŸºã¥ã„ã¦ä¾¡æ ¼ã‚’è¨­å®š
    base_price = 3000 if average_rating >= 4.0 else 2000 if average_rating >= 3.0 else 1500
    price_variation = random.randint(-500, 2000)
    price = max(500, min(50000, base_price + price_variation))

    now = datetime.now(timezone.utc)

    return {
        "productId": config["id"],
        "slug": config["slug"],
        "name": product_name,
        "category": category,
        "image": config["image"],
        "price": price,
        "description": description,
        "averageRating": average_rating,
        "totalReviews": len(reviews),
        "updatedAt": now,
        "createdAt": now,
    }


def match_review_to_product(record: Dict[str, object]) -> str | None:
    """ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æœ€ã‚‚é©åˆ‡ãªå•†å“ã«ãƒãƒƒãƒãƒ³ã‚°"""
    text = str(record.get("text", "")).lower()
    
    # å„å•†å“ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã®ãƒãƒƒãƒãƒ³ã‚°ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
    product_scores: Dict[str, int] = {}
    
    for product in PRODUCT_CONFIGS:
        score = 0
        for keyword in product["keywords"]:
            if keyword.lower() in text:
                score += 1
        if score > 0:
            product_scores[product["id"]] = score
    
    # æœ€ã‚‚ã‚¹ã‚³ã‚¢ãŒé«˜ã„å•†å“ã‚’è¿”ã™
    if product_scores:
        return max(product_scores.items(), key=lambda x: x[1])[0]
    
    return None


def collect_records(
    dataset_paths: Dict[str, Path],
    per_sentiment: int
) -> Dict[str, Dict[str, List[Dict[str, object]]]]:
    selected: Dict[str, Dict[str, List[Dict[str, object]]]] = {
        product["id"]: {"positive": [], "negative": []} for product in PRODUCT_CONFIGS
    }
    
    # å„å•†å“ã”ã¨ã«å¿…è¦ãªãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ã‚’è¿½è·¡
    required_counts = {product["id"]: per_sentiment for product in PRODUCT_CONFIGS}
    
    for _, record in iter_dataset(dataset_paths):
        label = int(record["label"])
        sentiment = classify_sentiment(label)
        if sentiment is None:
            continue
        
        # ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æœ€ã‚‚é©åˆ‡ãªå•†å“ã«ãƒãƒƒãƒãƒ³ã‚°
        matched_product_id = match_review_to_product(record)
        
        if matched_product_id:
            # å¿…è¦ãªãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ã«é”ã—ã¦ã„ãªã„å ´åˆã®ã¿è¿½åŠ 
            if len(selected[matched_product_id][sentiment]) < required_counts[matched_product_id]:
                selected[matched_product_id][sentiment].append(record)
        
        # ã™ã¹ã¦ã®å•†å“ã§å¿…è¦ãªãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ã«é”ã—ãŸã‹ãƒã‚§ãƒƒã‚¯
        all_complete = all(
            len(selected[product["id"]]["positive"]) >= required_counts[product["id"]]
            and len(selected[product["id"]]["negative"]) >= required_counts[product["id"]]
            for product in PRODUCT_CONFIGS
        )
        
        if all_complete:
            break
    
    # ä¸è¶³ã—ã¦ã„ã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è£œå®Œï¼ˆãƒãƒƒãƒãƒ³ã‚°ã§ããªã‹ã£ãŸãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ä½¿ç”¨ï¼‰
    unmatched_positives: List[Dict[str, object]] = []
    unmatched_negatives: List[Dict[str, object]] = []
    
    for _, record in iter_dataset(dataset_paths):
        label = int(record["label"])
        sentiment = classify_sentiment(label)
        if sentiment is None:
            continue
        
        matched_product_id = match_review_to_product(record)
        if not matched_product_id:
            if sentiment == "positive":
                unmatched_positives.append(record)
            else:
                unmatched_negatives.append(record)
    
    # ä¸è¶³åˆ†ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«è£œå®Œ
    random.shuffle(unmatched_positives)
    random.shuffle(unmatched_negatives)
    
    for product in PRODUCT_CONFIGS:
        product_id = product["id"]
        # è‚¯å®šãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ä¸è¶³åˆ†ã‚’è£œå®Œ
        while len(selected[product_id]["positive"]) < required_counts[product_id] and unmatched_positives:
            selected[product_id]["positive"].append(unmatched_positives.pop())
        # å¦å®šãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ä¸è¶³åˆ†ã‚’è£œå®Œ
        while len(selected[product_id]["negative"]) < required_counts[product_id] and unmatched_negatives:
            selected[product_id]["negative"].append(unmatched_negatives.pop())

    return selected


def ensure_records_sufficient(
    records: Dict[str, Dict[str, List[Dict[str, object]]]],
    per_sentiment: int
) -> None:
    shortages: List[str] = []
    for product in PRODUCT_CONFIGS:
        for sentiment in ("positive", "negative"):
            count = len(records[product["id"]][sentiment])
            if count < per_sentiment:
                shortages.append(f"{product['id']} ({sentiment}): {count}/{per_sentiment}")
    if shortages:
        message = "ååˆ†ãªä»¶æ•°ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åé›†ã§ãã¾ã›ã‚“ã§ã—ãŸ:\n  " + "\n  ".join(shortages)
        raise RuntimeError(message)


def upsert_products(db, product_documents: Dict[str, Dict[str, object]]) -> None:
    for product_id, document in product_documents.items():
        payload = document.copy()
        created_at = payload.pop("createdAt")
        payload["updatedAt"] = datetime.now(timezone.utc)

        db[COLLECTION_PRODUCTS].update_one(
            {"productId": product_id},
            {
                "$set": payload,
                "$setOnInsert": {"createdAt": created_at},
            },
            upsert=True,
        )


def insert_reviews(db, product_reviews: Dict[str, List[Dict[str, object]]], keep_existing: bool) -> None:
    for product in PRODUCT_CONFIGS:
        reviews = product_reviews.get(product["id"], [])
        if not reviews:
            continue
        if not keep_existing:
            db[COLLECTION_REVIEWS].delete_many({"productId": product["id"]})
        if reviews:
            db[COLLECTION_REVIEWS].insert_many(reviews)


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="SetFit/amazon_reviews_multi_jaãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’MongoDBã«æŠ•å…¥ã—ã¾ã™ã€‚"
    )
    parser.add_argument(
        "--data-dir",
        type=Path,
        default=Path("data/amazon_reviews"),
        help="ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª",
    )
    parser.add_argument(
        "--per-sentiment",
        type=int,
        default=30,
        help="å•†å“ã”ã¨ã«ç¢ºä¿ã™ã‚‹è‚¯å®š/å¦å®šãƒ¬ãƒ“ãƒ¥ãƒ¼ä»¶æ•°",
    )
    parser.add_argument(
        "--force-download",
        action="store_true",
        help="æ—¢å­˜ã®JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ããƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™",
    )
    parser.add_argument(
        "--keep-existing",
        action="store_true",
        help="æ—¢å­˜ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å‰Šé™¤ã›ãšã«è¿½åŠ ã—ã¾ã™ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ç½®ãæ›ãˆï¼‰",
    )
    parser.add_argument(
        "--mongodb-uri",
        default=os.environ.get("MONGODB_URI"),
        help="MongoDBã®æ¥ç¶šURIï¼ˆæœªæŒ‡å®šæ™‚ã¯ç’°å¢ƒå¤‰æ•°MONGODB_URIï¼‰",
    )
    parser.add_argument(
        "--mongodb-db",
        default=os.environ.get("MONGODB_DB_NAME", "review-system"),
        help="MongoDBã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åï¼ˆæœªæŒ‡å®šæ™‚ã¯ç’°å¢ƒå¤‰æ•°MONGODB_DB_NAMEã¾ãŸã¯review-systemï¼‰",
    )
    return parser.parse_args()


def main() -> None:
    args = parse_args()

    if not args.mongodb_uri:
        raise SystemExit("MongoDBã®æ¥ç¶šURIãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚--mongodb-uriã¾ãŸã¯ç’°å¢ƒå¤‰æ•°MONGODB_URIã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")

    mongodb_uri = args.mongodb_uri.strip().strip('"').strip("'")
    mongodb_db = args.mongodb_db.strip().strip('"').strip("'")

    dataset_paths = {
        split: args.data_dir / f"amazon_reviews_{split}.jsonl" for split in DATASET_URLS.keys()
    }

    print("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç¢ºèªã—ã¦ã„ã¾ã™...")
    for split, url in DATASET_URLS.items():
        download_file(url, dataset_paths[split], overwrite=args.force_download)
        print(f"  - {split}: {dataset_paths[split]}")

    print("\nğŸ” ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æŠ½å‡ºã—ã¦ã„ã¾ã™...")
    raw_records = collect_records(dataset_paths, args.per_sentiment)
    ensure_records_sufficient(raw_records, args.per_sentiment)

    product_reviews: Dict[str, List[Dict[str, object]]] = {product["id"]: [] for product in PRODUCT_CONFIGS}

    for product in PRODUCT_CONFIGS:
        index = 1
        for sentiment in ("positive", "negative"):
            for record in raw_records[product["id"]][sentiment]:
                review_doc = build_review_document(record, product, index, sentiment)
                product_reviews[product["id"]].append(review_doc)
                index += 1

    product_documents: Dict[str, Dict[str, object]] = {}
    for config in PRODUCT_CONFIGS:
        reviews = product_reviews.get(config["id"], [])
        if not reviews:
            continue
        product_documents[config["id"]] = build_product_document(config, reviews)

    # MongoDBæ¥ç¶šã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¨­å®šï¼ˆDNSè§£æ±ºã®å•é¡Œã‚’å›é¿ï¼‰
    client_options = {
        "serverSelectionTimeoutMS": 30000,  # 30ç§’
        "connectTimeoutMS": 30000,
    }
    
    # MongoDB Atlasã®å ´åˆã€Server APIã‚’æŒ‡å®š
    if "mongodb+srv://" in mongodb_uri:
        client_options["server_api"] = ServerApi("1")
    
    with MongoClient(mongodb_uri, **client_options) as client:
        # æ¥ç¶šãƒ†ã‚¹ãƒˆ
        try:
            client.admin.command("ping")
            print("âœ… MongoDBæ¥ç¶šã‚’ç¢ºèªã—ã¾ã—ãŸ")
        except Exception as e:
            print(f"âš ï¸  MongoDBæ¥ç¶šãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            print("æ¥ç¶šã‚’ç¶šè¡Œã—ã¾ã™ãŒã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™...")
        
        db = client[mongodb_db]
        upsert_products(db, product_documents)
        insert_reviews(db, product_reviews, keep_existing=args.keep_existing)

    print("\nâœ… ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ãŒå®Œäº†ã—ã¾ã—ãŸã€‚æ¦‚è¦:")
    for config in PRODUCT_CONFIGS:
        reviews = product_reviews[config["id"]]
        positives = sum(1 for review in reviews if review["sentiment"] == "positive")
        negatives = sum(1 for review in reviews if review["sentiment"] == "negative")
        name = product_documents.get(config["id"], {}).get("name", config["slug"])
        print(f"  - {name}: {len(reviews)}ä»¶ (positive {positives}, negative {negatives})")
    print("\nMongoDBã§ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨å¯èƒ½ã«ãªã‚Šã¾ã—ãŸã€‚")


if __name__ == "__main__":
    try:
        main()
    except Exception as exc:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {exc}", file=sys.stderr)
        sys.exit(1)

